{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSDS 7349 Anonymizing Data\n",
    "Authors: Alex Frye, Michael Smith, Lindsay Vitovsky\n",
    "\n",
    "## Introduction\n",
    "The Z-Virus has broken out in remote parts of the US. However, due to its incubation period, the virus was able to spread quickly before it was caught. The CDC in conjunction with the WHO have decided to realease sensitive healthcare data in an effort to crowdsource a solution to determine those attributes necessary to identify those immune to the disease and those that are carriers and their correlation with infected. With this data it may be possible to save the world by containing the diease before it spreads any further.\n",
    "\n",
    "## Creating a Dataset - Michael\n",
    "brief description of data created and process / references used.\n",
    "\n",
    "Demographic Data of Ethnicity and Age of USA: https://en.wikipedia.org/wiki/Demography_of_the_United_States  \n",
    "Hair and Eye Color data: http://www.gnxp.com/blog/2008/12/nlsy-blogging-eye-and-hair-color-of.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if os.path.isfile(\"dataset.csv\"):\n",
    "    print(\"Found the File!\")\n",
    "else:\n",
    "    %run constructDataSet.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "############################################################\n",
    "# Load the Compiled Data from CSV\n",
    "############################################################\n",
    "\n",
    "# Create CSV Reader Function and assign column headers\n",
    "def reader(f, columns):\n",
    "    d = pd.read_csv(f)\n",
    "    d.columns = columns\n",
    "    return d\n",
    "\n",
    "\n",
    "# Identify All CSV FileNames needing to be loaded\n",
    "path = r''\n",
    "all_files = glob.glob(os.path.join(path, \"dataset.csv\"))\n",
    "\n",
    "# Define File Columns\n",
    "columns = [\"ID\",\"LastName\", \"FirstName\", \"MiddleName\", \"Sex\", \"Age\", \"Ethnicity\", \"Hispanic_Latino\", \"BloodType\", \"HairColor\", \"EyeColor\", \"StreetAddress\", \"City\", \"State\", \"Zip\", \"PhoneNumber\", \"SocialSecurityNumber\", \"ZVirus\"]\n",
    "\n",
    "# Load Data\n",
    "Data = pd.concat([reader(f, columns) for f in all_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(Data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Anonymizing Data\n",
    "\n",
    "#### Personally Identifiable Information - Michael\n",
    "\n",
    "Last Name, First Name, Middle Name, Address, Phone Number and Social Security Number are all PII. First step in anonymizing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Output DataAnon as pd.frame\n",
    "\n",
    "DataAnon = Data[[\"ID\",\"Sex\", \"Age\", \"Ethnicity\", \"Hispanic_Latino\", \"BloodType\", \"HairColor\", \"EyeColor\", \"State\", \"ZVirus\"]]\n",
    "display(DataAnon.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Anonymization - Alex\n",
    "\n",
    "Age, Ethnicity, Blood Type, City, State and Zip could all be examined for K-Anonymization, removing those elements that have a low repetition count.\n",
    "\n",
    "Set K-Anonymization threshold to 5% of sample size. (AKA 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Define Threshold Value as 5% of Original Sample Size\n",
    "KAThres = round(len(Data) * .05, 0)\n",
    "print(KAThres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age\n",
    "Split up into categories so that no individual age can be taken advantage of. \n",
    "Identify counts for each class.\n",
    "the >=81 group does not meet the threshold, so values removed from dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "DataAnon[\"AgeClass\"] = np.where(DataAnon[\"Age\"] <= 20,                                                         \"<=20\",\n",
    "                                np.where((DataAnon[\"Age\"] >= 21) &  (DataAnon[\"Age\"] <= 40),                   \"21-40\",\n",
    "                                         np.where((DataAnon[\"Age\"] >= 41) &  (DataAnon[\"Age\"] <= 60),          \"41-60\",\n",
    "                                                  np.where((DataAnon[\"Age\"] >= 61) &  (DataAnon[\"Age\"] <= 80), \"61-80\",\n",
    "                                                                                                               \">=81\"\n",
    "                                                          )\n",
    "                                                 )\n",
    "                                        )\n",
    "                               )\n",
    "\n",
    "    #Agg Classes\n",
    "AgeAgg = pd.DataFrame({'count' : DataAnon.groupby([\"AgeClass\"]).size()}).reset_index()\n",
    "\n",
    "    # display class counts\n",
    "display(AgeAgg)\n",
    "    \n",
    "    # Pie class Distribution\n",
    "AgeAgg.plot.pie(y = 'count', labels = AgeAgg[\"AgeClass\"], autopct='%1.1f%%', figsize=(12,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    # MergeAgg\n",
    "DataAnon = pd.merge(DataAnon, AgeAgg, on = \"AgeClass\")\n",
    "\n",
    "    # Remove records with class count < Threshold Value\n",
    "DataAnon = DataAnon[DataAnon[\"count\"]>KAThres].drop(['Age', 'count'], axis = 1)\n",
    "\n",
    "print(\"After removing records of Age Groups with a group population less than {0}, we are left with {1} records.\".format(KAThres,len(DataAnon)))\n",
    "\n",
    "    #Agg Classes\n",
    "AgeAgg = pd.DataFrame({'count' : DataAnon.groupby([\"AgeClass\"]).size()}).reset_index()\n",
    "\n",
    "    # display class counts\n",
    "display(AgeAgg)\n",
    "\n",
    "del AgeAgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ethnicity\n",
    "Identify counts for each class.\n",
    "\n",
    "We remove Ethnicities: \"American Indian or Alaskan Native\"\n",
    "                       \"Asian American\"\n",
    "                       \"Native Hawaiian or Other Pacific Islander\"\n",
    "\n",
    "Should we just modify to \"other\"? so the records can stay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "    #Agg Classes\n",
    "EthAgg = pd.DataFrame({'count' : DataAnon.groupby([\"Ethnicity\"]).size()}).reset_index()\n",
    "\n",
    "    # display class counts\n",
    "display(EthAgg)\n",
    "    \n",
    "    # Pie class Distribution\n",
    "EthAgg.plot.pie(y = 'count', labels = EthAgg[\"Ethnicity\"], autopct='%1.1f%%', figsize=(12,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    # MergeAgg\n",
    "DataAnon = pd.merge(DataAnon, EthAgg, on = \"Ethnicity\")\n",
    "\n",
    "    # Remove records with class count < Threshold Value\n",
    "DataAnon = DataAnon[DataAnon[\"count\"]>KAThres].drop(['count'], axis = 1)\n",
    "\n",
    "print(\"After removing records of ethnicities with a group population less than {0}, we are left with {1} records.\".format(KAThres,len(DataAnon)))\n",
    "\n",
    "    #Agg Classes\n",
    "EthAgg = pd.DataFrame({'count' : DataAnon.groupby([\"Ethnicity\"]).size()}).reset_index()\n",
    "\n",
    "    # display class counts\n",
    "display(EthAgg)\n",
    "\n",
    "del EthAgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blood Type\n",
    "Identify counts for each class.\n",
    "\n",
    "We remove Blood Types: {AB+, AB-, B-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "    #Agg Classes\n",
    "BTAgg = pd.DataFrame({'count' : DataAnon.groupby([\"BloodType\"]).size()}).reset_index()\n",
    "\n",
    "    # display class counts\n",
    "display(BTAgg)\n",
    "    \n",
    "    # Pie class Distribution\n",
    "BTAgg.plot.pie(y = 'count', labels = BTAgg[\"BloodType\"], autopct='%1.1f%%', figsize=(12,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    # MergeAgg\n",
    "DataAnon = pd.merge(DataAnon, BTAgg, on = \"BloodType\")\n",
    "\n",
    "    # Remove records with class count < Threshold Value\n",
    "DataAnon = DataAnon[DataAnon[\"count\"]>KAThres].drop(['count'], axis = 1)\n",
    "\n",
    "print(\"After removing records of Blood Types with a group population less than {0}, we are left with {1} records.\".format(KAThres,len(DataAnon)))\n",
    "\n",
    "    #Agg Classes\n",
    "BTAgg = pd.DataFrame({'count' : DataAnon.groupby([\"BloodType\"]).size()}).reset_index()\n",
    "\n",
    "    # display class counts\n",
    "display(BTAgg)\n",
    "\n",
    "del BTAgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State\n",
    "Identify counts for each class.\n",
    "\n",
    "We leave all states due to the near-even distribution across state populations within our sample. Once we apply pertubation to the data, we suspect this attribute to be extremely difficult to identify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "    #Agg Classes\n",
    "SAgg = pd.DataFrame({'count' : DataAnon.groupby([\"State\"]).size()}).reset_index()\n",
    "\n",
    "    # display class counts\n",
    "display(SAgg)\n",
    "    \n",
    "    # Pie class Distribution\n",
    "SAgg.plot.pie(y = 'count', labels = SAgg[\"State\"], autopct='%1.1f%%', figsize=(12,6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hair Color\n",
    "Identify counts for each class.\n",
    "\n",
    "We remove Hair Colors: {Grey, Light Blond, Red}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "    #Agg Classes\n",
    "HairAgg = pd.DataFrame({'count' : DataAnon.groupby([\"HairColor\"]).size()}).reset_index()\n",
    "\n",
    "    # display class counts\n",
    "display(HairAgg)\n",
    "    \n",
    "    # Pie class Distribution\n",
    "HairAgg.plot.pie(y = 'count', labels = HairAgg[\"HairColor\"], autopct='%1.1f%%', figsize=(12,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    # MergeAgg\n",
    "DataAnon = pd.merge(DataAnon, HairAgg, on = \"HairColor\")\n",
    "\n",
    "    # Remove records with class count < Threshold Value\n",
    "DataAnon = DataAnon[DataAnon[\"count\"]>KAThres].drop(['count'], axis = 1)\n",
    "\n",
    "print(\"After removing records of Hair Color with a group population less than {0}, we are left with {1} records.\".format(KAThres,len(DataAnon)))\n",
    "\n",
    "    #Agg Classes\n",
    "HairAgg = pd.DataFrame({'count' : DataAnon.groupby([\"HairColor\"]).size()}).reset_index()\n",
    "\n",
    "    # display class counts\n",
    "display(HairAgg)\n",
    "\n",
    "del HairAgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eye Color\n",
    "Identify counts for each class.\n",
    "\n",
    "We remove Eye Colors: {Black, Grey, Light Blue, Light Brown, Other}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "    #Agg Classes\n",
    "EyeAgg = pd.DataFrame({'count' : DataAnon.groupby([\"EyeColor\"]).size()}).reset_index()\n",
    "\n",
    "    # display class counts\n",
    "display(EyeAgg)\n",
    "    \n",
    "    # Pie class Distribution\n",
    "EyeAgg.plot.pie(y = 'count', labels = EyeAgg[\"EyeColor\"], autopct='%1.1f%%', figsize=(12,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    # MergeAgg\n",
    "DataAnon = pd.merge(DataAnon, EyeAgg, on = \"EyeColor\")\n",
    "\n",
    "    # Remove records with class count < Threshold Value\n",
    "DataAnon = DataAnon[DataAnon[\"count\"]>KAThres].drop(['count'], axis = 1)\n",
    "\n",
    "print(\"After removing records of Eye Color with a group population less than {0}, we are left with {1} records.\".format(KAThres,len(DataAnon)))\n",
    "\n",
    "    #Agg Classes\n",
    "EyeAgg = pd.DataFrame({'count' : DataAnon.groupby([\"EyeColor\"]).size()}).reset_index()\n",
    "\n",
    "    # display class counts\n",
    "display(EyeAgg)\n",
    "\n",
    "del EyeAgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hispanic/Latino Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "    #Agg Classes\n",
    "HisAgg = pd.DataFrame({'count' : DataAnon.groupby([\"Hispanic_Latino\"]).size()}).reset_index()\n",
    "\n",
    "    # display class counts\n",
    "display(HisAgg)\n",
    "    \n",
    "    # Pie class Distribution\n",
    "HisAgg.plot.pie(y = 'count', labels = HisAgg[\"Hispanic_Latino\"], autopct='%1.1f%%', figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratification of the Response Variable or Classifier - Alex?\n",
    "\n",
    "By pulling equal distributions of each group, this changes the predictable distributions based on available population data.\n",
    "\n",
    "we want to create a stratified sample based on ZVirus type. When identifying how many records are remaining in each category, we find that the least frequent ZVirus type is \"Infected\" with a frequency of 1528. In order to stratify, this means we cannot have a sample size larger than 1528 * 3 = 4584. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "ZVirusDist = pd.DataFrame({'count' : DataAnon.groupby([\"ZVirus\"]).size()}).reset_index()\n",
    "display(ZVirusDist)\n",
    "\n",
    "ZVirusDist.plot.pie(y = 'count', labels = ZVirusDist['ZVirus'], autopct='%1.1f%%')\n",
    "\n",
    "del ZVirusDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to truly randomly sample observations from each class and keep a fairly round sample size number, we have chosen to utilize a stratified sample size of 3750. This sample size will be stratified three ways in a 33/33/33 split across the ZVirus classes. \n",
    "\n",
    "We are able to compute the sample size for each ZVirus type, and then take a random sample within each group. Below you will see that our sampled distribution matches the chosen 33/33/33 split across ZVirus types. \n",
    "\n",
    "*Note:* A seed value equal to the sample size of each type in order to ensure reproducibility for this report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "SampleSize = 3750\n",
    "\n",
    "CarrierSample_Seed   = int(round(SampleSize * 33.3333 / 100.0,0))\n",
    "ImmuneSample_Seed    = int(round(SampleSize * 33.3333 / 100.0,0))\n",
    "InfectedSample_Seed  = int(round(SampleSize * 33.3333 / 100.0,0))\n",
    "\n",
    "\n",
    "CarrierDataSampled  = DataAnon[DataAnon[\"ZVirus\"] == 'Carrier'].sample(n=CarrierSample_Seed, replace = False, random_state = CarrierSample_Seed)\n",
    "ImmuneDataSampled   = DataAnon[DataAnon[\"ZVirus\"] == 'Immune'].sample(n=ImmuneSample_Seed, replace = False, random_state = ImmuneSample_Seed)\n",
    "InfectedDataSampled = DataAnon[DataAnon[\"ZVirus\"] == 'Infected'].sample(n=InfectedSample_Seed, replace = False, random_state = InfectedSample_Seed)\n",
    "\n",
    "\n",
    "DataAnon = pd.concat([CarrierDataSampled,ImmuneDataSampled,InfectedDataSampled])\n",
    "\n",
    "print(len(DataAnon))\n",
    "\n",
    "ZVirusDist = pd.DataFrame({'count' : DataAnon.groupby([\"ZVirus\"]).size()}).reset_index()\n",
    "display(ZVirusDist)\n",
    "\n",
    "ZVirusDist.plot.pie(y = 'count', labels = ZVirusDist['ZVirus'], autopct='%1.1f%%')\n",
    "\n",
    "del ZVirusDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perturbation - Michael\n",
    "\n",
    "Removing identifiable feature names and values and translating them into non-sense that maintains the original distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Saving off a copy of the data set after our KA\n",
    "DataKAnon = DataAnon\n",
    "\n",
    "import hashlib\n",
    "\n",
    "salt = \"nintendo\"\n",
    "\n",
    "def hashbrowns(x):\n",
    "    tohash = (salt + str(x)).encode('utf-8')\n",
    "    return hashlib.sha256(tohash).hexdigest()\n",
    "\n",
    "columns_to_hash = [\"Sex\",\"Ethnicity\",\"Hispanic_Latino\",\"BloodType\",\"HairColor\",\"EyeColor\",\"State\",\"AgeClass\",\"ZVirus\"]\n",
    "for feature in columns_to_hash:\n",
    "    DataAnon[feature] = DataAnon[feature].apply(hashbrowns)\n",
    "\n",
    "display(DataAnon.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deanonymizing Data\n",
    "\n",
    "#### Is Stratification and K-Anonymization after removing PII sufficient?\n",
    "\n",
    "* Compare anonymized data with original data set\n",
    "* Look at knowable demographic distributions\n",
    "* Are there outliers that K-Anonymization missed?\n",
    "* Do combinations of columns/features result in identifiable or recognizable observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perturbation\n",
    "\n",
    "* Computers don't need to know the semantic meaning of a value to understand its distribution\n",
    "    * Linear vs Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cracking the Hash\n",
    "\n",
    ">A note on this process: We used a weak hashing method on purpose to illustrate a possible method of attack. A cryptographically secure method would not use a dictionary based salt, nor would that salt be static and independent of both the generator of the dataset and the recipient of the downloaded dataset.\n",
    "\n",
    "Essentially, what we're attempting to do is create a forced hash collision by using what we know about the data. For example, both the Hispanic_Latino and the Sex columns appear to be binary and since they have the same hash values in each, it's likely that whatever value is in one column should be equivalent to the value in the other. This means values like Y or N, and Yes and No are unlikely. This leaves us with context neutral classifier values such as 0 or 1. If they didn't have the same value, it would be simpler to begin with the Sex column as its likely possible values are much narrower: 0 or 1, Male or Female, m or f, and other variations.\n",
    "\n",
    "The first step is to copy and paste our given hashes into google search. This will let us know if the hashes have already been calculated before, and if they have, what the value is. A quick search of \"ddebf4bb08617e33fac3c0e43ea5c3f63df912887f984d80d61d4b685a036dc3\" turned up zero results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#from itertools import product\n",
    "#import string\n",
    "#\n",
    "#chars = string.ascii_lowercase # chars to look for\n",
    "#\n",
    "#for length in range(5, 10): # only do lengths of 1 + 2\n",
    "#    to_attempt = product(chars, repeat=length)\n",
    "#    for attempt in to_attempt:\n",
    "#        if (attempt == \"nintendo\"):\n",
    "#            print(\"Found It.\")\n",
    "#            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "f = open(\"10k_most_common.txt\",\"r\")\n",
    "passwords = f.readlines()\n",
    "f.close()\n",
    "\n",
    "possibleValues = ['0','1']\n",
    "valueTest = DataAnon[\"Hispanic_Latino\"][0]\n",
    "\n",
    "for password in passwords:\n",
    "    password = password.strip('\\n')\n",
    "    for value in possibleValues:\n",
    "        saltBefore = (password + str(value)).encode('utf-8')\n",
    "        saltAfter = (str(value) + password).encode('utf-8')\n",
    "        \n",
    "        if (hashlib.sha256(saltBefore).hexdigest() == valueTest or hashlib.sha256(saltAfter).hexdigest() == valueTest):\n",
    "            print(\"Password is: \" + password)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Password and Hash method now known, we can begin our attempts to guess the remaining data set. While hash functions are normally one way, as long as we know some basic meta information about the dataset it becomes possible to decode other attributes as it's much easier to guess the values of classifiers than it is to guess the salt for a hash.\n",
    "\n",
    "In the case of ZVirus classification, we know that the CDC has been labeling their statistics and graphs with Carrier, Immune and Infected. So it's likely that these three values were used in this dataset especiall as it contains three unique classifiers in the ZVirus column. Of course it's possible they used non-contextual based classifiers such as 0, 1, 2, etc. Or even used partial contextual classifiers like C, Im, In. As always, start with the obvious, and work your way down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hashdebrown(hashvalue,possibleValues):\n",
    "    password = \"nintendo\" #taken from earlier\n",
    "    for value in possibleValues:\n",
    "        saltBefore = (password + str(value)).encode('utf-8')\n",
    "        saltAfter = (str(value) + password).encode('utf-8')\n",
    "        \n",
    "        #sha256, again, taken from above\n",
    "        if (hashlib.sha256(saltBefore).hexdigest() == hashvalue or hashlib.sha256(saltAfter).hexdigest() == hashvalue):\n",
    "            return [hashvalue,value]\n",
    "    return [hashvalue,\"Unknown\"]\n",
    "\n",
    "#According to the CDC, they've been classifying people as Carrier, Immune or Infected\n",
    "ZVirusValues = [\"Carrier\",\"Immune\",\"Infected\",\"0\",\"1\",\"2\",\"C\",\"Im\",\"In\"]\n",
    "for hashvalue in DataAnon['ZVirus'].unique():\n",
    "    print(str(hashdebrown(hashvalue,ZVirusValues)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
