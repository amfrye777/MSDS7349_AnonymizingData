


\documentclass[10pt,journal,compsoc]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[10pt,journal,compsoc]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.
%
% Note that some packages require special options to format as the Computer
% Society requires. In particular, Computer Society  papers do not use
% compressed citation ranges as is done in typical IEEE papers
% (e.g., [1]-[4]). Instead, they list every citation separately in order
% (e.g., [1], [2], [3], [4]). To get the latter we need to load the cite
% package with the nocompress option which is supported by cite.sty v4.0
% and later. Note also the use of a CLASSOPTION conditional provided by
% IEEEtran.cls V1.7 and later.





% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex






% *** MATH PACKAGES ***
%
%\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a sans serif font rather
% than the serif font used in traditional IEEE formatting and thus the need
% to invoke different subfig.sty package options depending on whether
% compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley, Jeff Goldberg and 
% Axel Sommerfeldt. This package may be useful when used in conjunction with 
% IEEEtran.cls'  captionsoff option. Some IEEE journals/societies require that
% submissions have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.4.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/pkg/endfloat
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a 
% page by themselves.




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.





% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Anonymization of Data\\MSDS 7349 Project Draft}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%
%
%\IEEEcompsocitemizethanks is a special \thanks that produces the bulleted
% lists the Computer Society journals use for "first footnote" author
% affiliations. Use \IEEEcompsocthanksitem which works much like \item
% for each affiliation group. When not in compsoc mode,
% \IEEEcompsocitemizethanks becomes like \thanks and
% \IEEEcompsocthanksitem becomes a line break with idention. This
% facilitates dual compilation, although admittedly the differences in the
% desired content of \author between the different types of papers makes a
% one-size-fits-all approach a daunting prospect. For instance, compsoc 
% journal papers have the author affiliations above the "Manuscript
% received ..."  text while in non-compsoc journals this is reversed. Sigh.

\author{Alex~Frye,
        Michael~Smith,
        and~Lindsay~Vitovsky% <-this % stops a space
\protect\\
% note need leading \protect in front of \\ to get a newline within \thanks as
% \\ is fragile and will error, could use \hfil\break instead.

\thanks{Alex Frye, amfrye@smu.edu} \thanks{Michael Smith, michaelsmith@smu.edu} \thanks {Lindsay Vitovsky, lvitovsky@smu.edu}}

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers
\markboth{Frye, Smith, Vitovsky MSDS 7349 Project 1 Draft}%
{Shell \MakeLowercase{\textit{et al.}}: }
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.



% The publisher's ID mark at the bottom of the page is less important with
% Computer Society journal papers as those publications place the marks
% outside of the main text columns and, therefore, unlike regular IEEE
% journals, the available text space is not reduced by their presence.
% If you want to put a publisher's ID mark on the page you can do it like
% this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2015 IEEE}
% or like this to get the Computer Society new two part style.
%\IEEEpubid{\makebox[\columnwidth]{\hfill 0000--0000/00/\$00.00~\copyright~2015 IEEE}%
%\hspace{\columnsep}\makebox[\columnwidth]{Published by the IEEE Computer Society\hfill}}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark (Computer Society jorunal
% papers don't need this extra clearance.)



% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}



% for Computer Society papers, we must declare the abstract and index terms
% PRIOR to the title within the \IEEEtitleabstractindextext IEEEtran
% command as these need to go into the title area created by \maketitle.
% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\IEEEtitleabstractindextext{%
\begin{abstract}
Big data certainly brings with it a series of challenges, one of them being privacy of these large data sets.  In the name of scientific progress, an amazing number of data sets have been released as a way to promote collaboration and development of the data science community.  This paper critically reviews an array of anonymization theories and techniques, applying them to real-world situations, with the goal of helping others weigh the cost, benefit, and, most importantly, the ethics of anonymizing data.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
micro-data, k-anonymization, quasi-identifiers, unique identifiers, personal ly identifiable information (PII), high-dimensional data sets, sparcity
\end{IEEEkeywords}}


% make the title area
\maketitle


% To allow for easy dual compilation without having to reenter the
% abstract/keywords data, the \IEEEtitleabstractindextext text will
% not be used in maketitle, but will appear (i.e., to be "transported")
% here as \IEEEdisplaynontitleabstractindextext when the compsoc 
% or transmag modes are not selected <OR> if conference mode is selected 
% - because all conference papers position the abstract like regular
% papers do.
\IEEEdisplaynontitleabstractindextext
% \IEEEdisplaynontitleabstractindextext has no effect when using
% compsoc or transmag under a non-conference mode.



% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\IEEEraisesectionheading{\section{Introduction}\label{sec:introduction}}
% Computer Society journal (but not conference!) papers do something unusual
% with the very first section heading (almost always called "Introduction").
% They place it ABOVE the main text! IEEEtran.cls does not automatically do
% this for you, but you can achieve this effect with the provided
% \IEEEraisesectionheading{} command. Note the need to keep any \label that
% is to refer to the section immediately after \section in the above as
% \IEEEraisesectionheading puts \section within a raised box.




% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps (small caps for compsoc).
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by the IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.
\IEEEPARstart{O}{N} September 18, 2009, Netflix announced the winner of its “Netflix Prize competition”, a contest that asked contributors to improve upon its existing algorithm that predicted subscribers future movie ratings.  With a prize of \$1,000,000, the competition certainly attracted many groups from all over the globe.  In the end, Netflix received 44,014 submissions from 41,305 teams, all who had analyzed the seemingly anonymized dataset of over 100,000,000 movie ratings by Netflix subscribers.

According to the Netflix Prize website, which was still live at the time of this paper, “The data were collected between October, 1998 and December, 2005 and reflect the distribution of all ratings received by Netflix during this period. The ratings are on a scale from 1 to 5 (integral) stars. To protect customer privacy, all personal information identifying individual customers has been removed and all customer ids have been replaced by randomly-assigned ids. The date of each rating and the title and year of release for each movie are provided. No other customer or movie information is provided.“
	
Unfortunately for Netflix, resulting from this contest was a lawsuit for releasing this data, and an investigation by the Federal Trade Commission.    Apparently, one actually could identify actual users from this data set, as proven by two University of Texas researchers in 2008 \cite{narayanan}.  To make matters worse, Netflix did not end up using the winning algorithm, citing “engineering” challenges and the fact that their model was rapidly changing from DVDs to streaming\cite{johnston}.

The repercussions from this anticlimax caused Netflix to cancel its Netflix Prize 2, drawing both praise and criticism.  Simply reading the comments section of various online articles covering this news reveals the various viewpoints of the importance (or non-importance) of privacy in today’s cyber world.  

\begin{center}
\textit{"I really don't see the problem with this..." \\– Killer Orca}\cite{anderson}

\vspace{2mm}

\textit{"You would think with that huge privacy snafu AOL had with their ‘anonymized’ search data that someone at Netflix would have realized this was a bad idea." \\– ozziegt}\cite{anderson}

\vspace{2mm}

\textit{"Just some lawyers looking for profit, hugely inflating the risks…" \\– Anonymous}\cite{cheng}

\vspace{2mm}

\textit{"Whether you consider it offensive or not should be irrelevant; if the data is private, they can’t 
give it away." \\– danchr}\cite{ohm}

\end{center}

Even if Netflix had obtained user permission to release these ratings (which they did not), those who opted in surely would not have surmised that they could have been identified personally by a complete stranger unaffiliated with Netflix.  Certainly, Netflix would have assured that their ratings were anonymized, since that is what it believed to be the case as well. The trust that the subscribers would have placed in Netflix to better their experience, without compromising their privacy, would have been misplaced.
	
Today, there are several popular techniques for anonymizing data sets, but none are perfect.  Certain methods may work for a particular sized set of records, only to lose its credibility as that set scales over time.  Others may change the data so much that its dramatically declines to a data scientist. Is true anonymization even possible in this cyber world? The ability to pull public information from outside sources, to then match it with private data sets, has proven to be a very dangerous risk for institutions and the individuals that have entrusted them.
	
Our team seeks to investigate these most popular methods, weighing their effectiveness in regards to: 1) the size of a data set, 
2)	the data type (i.e. categorical v. numerical attributes,
3)	the effect on data science results (i.e. is there a change to a 95\% confidence interval because of the perturbation?),
4)	deployment in various industries, particularly the medical and financial fields due to their collection of personal information and regulatory oversight.  We will then try to anonymize a data set we created, investigating how easy or difficult it is to garner identifying information from something seemingly innocuous.  Ultimately, we make final recommendations to the reader as to what we believe are essential questions a company should be reflecting upon as they consider their privacy policies and procedures.

% You must have at least 2 lines in the paragraph with the drop letter
% (should never be an issue)


\hfill 
 
\hfill 

\subsection{Background}

% needed in second column of first page if using \IEEEpubid
%\IEEEpubidadjcol

\subsubsection{Existing Research / Techniques}

	Before traveling too much further into these methods, it warrants mentioning that privacy itself has yet to be universally defined. One could say that privacy is when non-public information is made available to a third party, such as a social security number or the results from a medical test.  This insinuates that the nature of the data is what determines the need for privacy.  But what about those pesky ads that pop up on a smart phone?  Ads are to be expected, but what if they directly reflect the search history a user performed on a completely different device?  The discussion of what privacy means, particularly what a user authorizes others to collect, store and share, has yet to be answered in a world where mobile devices outnumber humans\cite{borne}. There are many individuals who would tell you that they feel their privacy has been violated by this collection and use of their search data.
	
	Of equal concern to the authors is the other end of the spectrum, which is the evidently voluntary surrender of the collection and use of one's data.  There are a large number of users who do not seem to take issue with their non-personal data being stored or sold to other companies.  The task of maintaining privacy is certainly overwhelming, and perhaps this is why so many users throw up a white flag and say, "Who cares?"  Perhaps, they simply do not want to think about the data that is out there, since there is presumably nothing that can be done about it.
	
	Adding on to this acceptance of the release of “unimportant” data is the common misconception that less privacy means more security.  When the FBI very publicly condemned Apple for not helping it unlock an iPhone that belonged to a gunman who helped kill fourteen people in San Bernardino, CA in 2015, there were many people who joined the FBI in the criticism.  The reality is that these keys to our privacy are not held behind a locked safe, guarded by trustworthy individuals.  Often our privacy is protected simply on an agreement of trust.  Not only would the FBI now have known how to unlock an iPhone, but there would have been employees of Apple that would have then been privy to the information as well.  Our message here is that the bounds around privacy should not be thought of as well-defined.  The questions must be asked so that those involved can properly reflect on the danger of using anonymized data and weigh it against any supposed benefit.
	
\subsection{Testing of a Dataset}
To experience an anonymization as well as de-anonymization for ourselves, we created a fake data set of 4,000 records.  The attributes included are:

\begin{table} [ht]
\caption{Dataset Attributes}
\begin{tabular}{|l|l|}
\hline
Name & string divided into first name, middle name,\\ & and last name\\
\hline
Sex & categorical of male or female\\
\hline
Age & numerical\\
\hline
Ethnicity / race & categorical\\
\hline
Hispanic / Latino & binary categorical yes / no\\
\hline
Hair color & categorical\\
\hline
Eye Color & categorical\\
\hline 
Address & string\\
\hline
Phone number & string\\
\hline

\end{tabular}
\end{table}

This data set was generated randomly, and provides us with several opportunities to try common anonymization techniques discussed in this paper.  The attributes were chose to reflect common member records that would go under de-identification methods such as 1) changing addresses to zip codes, 2) changing specific ages to an age range, 3) keeping only the area code of a phone number, 4) removing all names and replacing with one field of an assigned identification number, and 5) dividing the columns into less comprehensive tuples.


\subsubsection{Analysis of Existing Techniques}

	Of particular interest to our paper were some of the more frequently employed anonymization techniques.  To be clear, our definition for these techniques fall more into the realm of “attempts” as it has been well documented that anonymization has continued to elude the cyber community [ENTER SEVERAL ENDNOTES OF OUR PAPERS WE READ, XIANG BAI-LI, LOUKIDES and NARAYANAN].  \linebreak
	

\noindent \textbf{K-anonymization}

	In researching k-anonymization, this technique is most widely used as a method for maintain as much statistical integrity.  By removing instances with less than k number of matching records, the data set seeks to protect the ease of finding “loners” by taking them out altogether.  For example, if you have 30,000 surgery patients, and all personal information has been removed, then it is possible to have multiple instances of the same data (i.e. twelve gallbladder removal surgeries).  However, as documented by Greg Loukides’ team,  the efficacy of this method on large sets of “anonymized data”  has its challenges\cite{loukides}.  K-anonymization acknowledges that those records that do not appear as often are at increased risk of being re-identified, so unless that record has k number of other records like it, it is removed.  While theoretically sound, the disadvantages are the computational power required on large data sets to find these counts, and the assumption that the remaining tuples are measurably more difficult to match to additional data.  
	
	Perhaps the domain comes into play here.  For medical information, physical attributes and maladies can often be accompanied by other instances of care.  It would be wise for those storing this data to understand the overall web of available data on someone who might only be treated for an infection.  This patient will most likely be prescribed antibiotics, which means there might be pharmacy information to match.   Consider a more multi-symptomatic  issue – high blood pressure.  Suppose a patient was being treated for this, but by his or her psychotherapist?  Now we have potentially devastating information that could alert someone in this person’s circle of friends, family, and work colleagues of a mental illness.
	
	The benefit of k-anonymization is not be ignored, however.  It certainly helps to avoid making the easiest to identify as low hanging fruit.  The benefit to statistical analysis is also to be given credit.  While one would not have the nuanced meaning that outliers can bring, with data sets being so large, the argument stands that these “one offs” can be ignored with the same level of confidence.
[Try this on our data set?]
\linebreak

\noindent \textbf{Sparse Data Sets}

	Heavily used by many large corporations including Amazon, sparse data sets have become a very prevalent way to store tuples\cite{narayanan,gentry,rimes}.  Sparse data is kept in a much less comprehensive form, only confessing a small number of attributes per record.  This results in many more records, perhaps duplicate records, and a harder time for adversaries to draw connections among the many tuples.
	
	As tested by Narayanan and Shmatikov, this method has its drawbacks as well.  As the data set grows, it is easier for an adversary to find patterns and relationships in sparse data.  We liken it to the experience of purchasing groceries.  The cashier (or you, if you find yourself at a self-checkout kiosk) can either place many items in few bags, or only a few items inside of many bags.  Say you wanted to pull out all of the fruit.  If there are only a few items per bag, a literal “GROUPBY” function is easier with smaller bags as you can quickly see what is in each bag.  Conversely, if you were to have the bags with many items in them, the more bags you have, the longer it is going to take you to go through each one.  If there were only two or three bags with many items, it would not be a large task compared to the other method.  However, in the same way that large data sets continue to grow, if you now have to look through fifteen or twenty bags, it might take significantly longer just in processing time.
	
	Is this a textbook case of \textit{a priori}?  It seems absolutely foolish to contain too much information in a record.  One would be giving adversaries much more data to work off of and not making them look for it. But is this the real world scenario? Perhaps the answer is in the nature of the data.  Sparse data has been adopted as much safer than comprehensive, and to us, it makes sense.  Data engineers are then tasked with comprehending 1) what they know about the data relationships, and 2) what an adversary might know.  If relationships are hard to draw conceptually, sparse data is more robust to attacks.  However, if each tuple is simple in nature, such as purchases for an online retailer, a company would just need to employ additional measures to further mask the data.  Knowing that an anonymous user’s high blood pressure diagnosis is linked to depression is perhaps a harder reach than, say, knowing someone who purchased milk most likely also bought cereal, children’s foods, or beer on the same visit.
	  
	Of course, armed with additional, outside data, such as credit card transactions for a certain zip code, this situation become even more vulnerable.  Regarding the blood pressure scenario from above, perhaps an adversary knows from this outside data, the purchase amount at a pharmacy.  He or she sees that this amount is very large, and the patient most likely picked up additional items.  Even armed with this limited information, an adversary could begin formalizing guesses at to other needs this person had.  Indeed, Narayanan and Shmatikov proved how adversaries knowing very little of the data, or even what they were looking for, could use these generalities to completely re-identify a user\cite{narayanan}.
\linebreak	
\noindent \textbf{Perturbation}

	Another method used to anonymize data is to actually change the attributes enough to create further distance from a given source, but not so much as to statistically alter data science efforts.  Common examples are to create ranges and categories out of numerical fields, or to use internal identifiers instead of more publicly recognizable attributes.  In fact, perturbation is also used as a way to actually detect data leaks,  based on the theory that if a particular recipient is given a data set that was perturbed with a certain dictionary of identifiers, and this information is found somewhere it should not have been, you can determine which party released the data since there is no other recipient that had that particular set of identifiers.
	
	Common examples of perturbation include:\linebreak
	
	* Removing Personal Identifiable Information (PIIs) and replacing with an ID number. \linebreak
	
	* Taking a scalar value and applying ranges.  Instead of ages, the owner of the data could use age ranges that mask the exact answer.\linebreak
	
	* Selectively altering or even deleting data to create doubt in a bad actor.  If a malicious party has, say, matched up a perturbed data set with another set found online, the principle here is that they have a reduced chance of correctly determining a subject's attribute values.  
	* Changing the definition of certain attributes.  For example, if the need for a data set is to review density of certain attributes, then it does not matter if the values reflect the original values.  As long as the correct scale is used, one could change, say, zip codes to names of fruits and vegetables.  Of course, this might cause more confusion than value depending on the purpose of the data mining activity, so the owner of the data would need to know the purpose of a data scientist to correctly perform this technique.\linebreak
	
	* Use a "watermark" to discourage data leaks.  Watermarking involves altering the data to embed a secret code per subset / data set that is given out.  This helps a data source know who leaked a data set because each recipient received a different watermark.\linebreak
	
	Of course, no method is perfect, and neither is perturbation.  If one does not consider \textit{why} a data set is needed, perturbing certain fields could make the data unusable.  The number of fields released directly affects the strength of a perturbed attribute.  500,000 records with their ages changed to age ranges is very different from 100 records.  The more a malicious attacker would has to work with, the greater the chance that he or she can figure out a "secret" alteration method, especially if that field is now a category where there are not as many "wrong answers".  Remember, an attacker does not necessarily have to be exactly right in their guess.  Even having a broad guess of where someone might fall has been proven dangerous to the confidentiality of a data set, as evidenced by the Netflix prize fiasco \cite{narayanan}.  Finally, watermarks are not effective if an attacker has discovered how to delete it.  
	
	Perturbation is certainly a way to cause doubt for an attacker, but it must be taken into consideration with other factors.  The size of the data set, distribution of the various attribute values, and the confusion it could cause for a data scientist indicate that additional techniques and factors need to be considered before this method is held up as the solution to a problem.\linebreak

\noindent \textbf{Deletion of Data}

	Similar to perturbation, deletion of data alters a data set, if not completely eliminates it.  One might wonder what the point is, since deleting a data set would effectively make it anonymous, but there are interesting results from this method that warrant further explanation.
	
	Firstly, virtual deletion of part of a data set is routinely performed by creating subsets. Here you limit what is given out to reduce the chances of identifying a subject.  This is, of course, a sparse data set technique.  However, what if an entity actually truly deleted attributes permanently in the interest of protecting more sensitive fields?  
	
	For example, say there is a medical data set that held information showing subjects' zip codes, ages, names of hospitals visited,  number of days they were in the hospital, and the diagnostic codes of whatever they were were in the hospital for.  Is is imperative that we have a subject's zip code?  Is knowing the hospital visited essentially the same thing and would this be enough for the quesion at hand?  But does knowing the hospital \textit{likely} to give away a zip code anyway, in which case perturbation of the hospital name would be necessary?
	
	To make matters more challenging, permanent deletion of data, especially partial, can create a new host of problems for databases.  Indexing can be disturbed if too many records are deleted, resulting in energy waste as a database interface searches through empty locations.  Keys (or lack thereof) also present a problem.  Deleting a field such as a social security number might seem like a reasonable idea, but if that field serves as at least one primary key in any of the database records, the results could be catastrophic.\linebreak

	That being said, in an age where data leaks have put consumers at risk and hurt various companies bottom lines (think Yahoo!'s reduced purchase price following a data breach \cite{albanesius} , is deletion of data actually a good move to create good will? While "Big Data" seems to be at the forefront of many companies' minds, many entities seem to have an inability to handle it against malicious attacks.  Perhaps a company could receive more value from promoting that they \textit{delete} data instead of store it.  This would take a commitment and understanding well in advance of a database design to avoid operational impediments, or simply enough flexibility that a corporation could actually do this without putting themselves at more risk of net lost sales or decreased operational efficiency.


\section{De-anonymization}
	To gain a better understanding of how effective various anonymization techniques are, our team explored de-anonymization methods as well.  We did this by reading existing papers and articles and by actually testing certain de-anonymization processes on our sample data set.
	The following points are worth noting as background knowledge before any type of de-anonymization. \linebreak

	*\textbf{Assumptions of an adversary's knowledge:} a bad actor might have only general knowledge about the fields in a data set.  It is not impossible for someone to explore a data set and find likely identifiers with what they deem as a satisfactory level of confidence.  Therefor, just because an exact value cannot be determined by an attacker, a general idea might be enough for their uses.\linebreak
	
	\textbf{Acceptance of the power of data:}  a simple gut check of "what could one possibly get out of this data?" is not a valid test against the vulnerability of a data set.  As evidenced by the Netflix prize de-anonymization, Narayanan and Shmatikov were able to take seemingly innocuous information and tie it back to names individuals. \cite{narayanan}  To assume that data is not "important enough" or too "vague" could be considered gross negligence in this age of digital security enlightenment. \linebreak
	
	\textbf{Acknowledgment of the repercussions of shared data:} it is important to know that implications exist for subjects whose data is known by others.  Being able to identify who someone is based on their movie reviews may seem harmless, but in the wrong hands, it could be used to punish someone for their political or religious views.  For those who would balk at the weight of such a discovery, the ability to then match up names with another publicly available data set, could truly make this situation a nightmare for a company. 
	
	Additionally, once an attacker has at least something to work with, even just a name, there is a myriad of other activities one could perform to gain additional knowledge on a data set.  For example, an attacker can make physical phone calls or send electronic messages to various parties to retrieve additional knowledge on a very small piece of information they garnered from a dataset.  They can then return to that same data set or another data set with this more complete picture of a subject's life to find out additional information.  In other words, an attacker's knowledge of a data set is not necessarily limited to mining data sets.\linebreak
	
	\textbf{Algorithms can be your enemy:} for an adversary with limited knowledge about the subjects or data set, an algorithm can speed up their investigation and narrow down the list of possible values. In fact, it was an algorithm that helped Narayanan and Shmatikov gain significant progress in connecting subjects with their data.  For those adversaries who are not working with much information to start with, but who have an effective algorithm, they are no longer looking for a needle in a haystack.\linebreak

\subsubsection{Testing of De-anonymization on Our Data Set}
	
	
 How our data set might be compromised by an adversary\\
\indent i. real-world implications of re-identification\\
\indent ii. least likely and most likely de-anonymization risks\\
\section{Recommendation}

	It is not reasonable to avoid data collection and sharing altogether.  Thus, we have compiled a series of recommendations that we would advise to those interested in having a better realization of the remaining vulnerability of their anonymization techniques.\linebreak
	
1. Actively attempt to de-anonymize data sets.  Depending on the sensitivity of the data, this might need to be performed by individuals not privvy to the anonymization processes used.\linebreak

2.  Put aside personal bias, and spend time exploring the danger of a data set's attributes being known.  A "once over" is not enough.  Seemingly innocuous data can actually be harmful if in the wrong hands.\linebreak

3.  Consider using multiple anonymization techniques.  Test along the way to see how this affects statistical analysis.\linebreak

4.  Work to understand the goal of a data mining activity before providing data sets. Consider using subsets, and weigh the the value of data mining activities with the vulnerability of the subjects' information.\linebreak

5.  Consider the long range goals of an organization before employing the use of public contests.  Will you even need this winning algorithm or model in the long term?



% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.
% However, the Computer Society has been known to put floats at the bottom.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.




\section{Conclusion}
Where our amazing conclusion will go.

\newpage
% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%


\appendices
\section{}
placeholder

% you can choose not to have a title for an appendix
% if you want by leaving the argument blank
\section{}
placeholder


% use section* for acknowledgment
\ifCLASSOPTIONcompsoc
  % The Computer Society usually uses the plural form
  \section*{Acknowledgments}
\else
  % regular IEEE prefers the singular form
  \section*{Acknowledgment}
\fi


The authors would like to thank...\\
The IEEE for this template, TRANS-JOUR.DOC


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\begin{thebibliography}{9}
\bibitem{narayanan}
Narayanan, Arvind and Vitaly Shmatikov \emph{Robust De-anonymization of Large Sparse Datasets}. \hskip 1em plus 0.5em minus 0.4em\relax SP ’08 Proceedings of the 2008 IEEE Symposium on Security and Privacy. 2008.

\bibitem{johnston}
Johnston, Casy. \emph {Netflix Never Used Its \$1 Million Algorithm Due to Engineering Costs}. \hskip 1em plus 0.5em minus 0.4em\relax Wired Magazine. https://www.wired.com/2012/04/netflix-prize-costs/.  April 2012.

\bibitem{anderson}
Anderson, Nate. \emph {Neflix Prize 2 (Privacy) Apocalpyse Now?}\hskip 1em plus 0.5em minus 0.4em\relax  ars Technica.  https://arstechnica.com/tech-policy/2009/09/netflix-prize-2-privacy-apocalypse-now/?comments=1. September 2009.

\bibitem {ohm}
Ohm, Paul.  \emph{Netflix Cancels the Netflix Prize 2}. \hskip 1em plus 0.5em minus 0.4em\relax Freedom to Tinker.com. https://freedom-to-tinker.com/2010/03/12/netflix-cancels-netflix-prize-2/. March 2010.


\bibitem{cheng}
Cheng, Jacqui. \emph{Netflix settles privacy lawsuit, ditches \$1 million contest}. \hskip 1em plus 0.5em minus 0.4em\relax ars Technica. https://arstechnica.com/tech-policy/2010/03/netflix-ditches-1-million-contest-in-wake-of-privacy-suit/?comments=1.  March 2010.

\bibitem {borne}
Borne, Zachary Davies. \emph{There Are Officially More Mobile Devices Than People in the World}. \hskip 1em plus 0.5em minus 0.4em\relax  Independent.co.uk.  http://www.independent.co.uk/life-style/gadgets-and-tech/news/there-are-officially-more-mobile-devices-than-people-in-the-world-9780518.html. October 2014.

\bibitem{loukides}
Loukides, Grigorios Aris Gkoulalas-Divanis, and Bradley Mali. \emph{Anonymization of electronic medical records for validating genome-wide association studies}. \hskip 1em plus 0.5em minus 0.4em\relax Proceedings of the National Academy of Sciences of the United States of America. Vol. 107, No. 17, pp 7898-7903.  April 2010. 

\bibitem {gentry}
Gentry, Jerry. \emph {Big Data vs. Sparse Data}. \hskip 1em plus 0.5em minus 0.4em\relax Data Center Knowledge.  http://www.datacenterknowledge.com/archives/2012/10/11/big-data-versus-sparse-data/.  October 2012.

\bibitem {rimes}
Rimes. \emph{The difference between "dense" and "sparse" data}.  \hskip 1em plus 0.5em minus 0.4em\relax.  Rimes.com.  https://www.rimes.com/insights/the-difference-between-dense-and-sparse-data/.  February 2012.
  
\bibitem{kopka}
H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus 0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

\bibitem{albanesius}
Albanesius, Chloe. \emph{After Breach, Verizon Drops Yahoo Purchase Price by \$350M}. \hskip 1em plus 0.5em minus 0.4em\relax PC News. 1em plus 0.5em minus 0.4em\relax. February 2017.



\end{thebibliography}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

%\begin{IEEEbiographynophoto}{Alex Frye}
%Biography text here.
%\end{IEEEbiographynophoto}

% if you will not have a photo at all:
%\begin{IEEEbiographynophoto}{Michael Smith}
%Biography text here.
%\end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

%\begin{IEEEbiographynophoto}{Lindsay Vitovsky}
%Biography text here.
%\end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


